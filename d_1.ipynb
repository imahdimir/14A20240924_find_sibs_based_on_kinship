{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create an instance on RAP then connect the current notebook to the instance."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%bash\n",
    "pip install dxpy"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T17:49:08.735071Z",
     "start_time": "2024-09-29T17:49:08.480746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%bash\n",
    "dx login "
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquiring credentials from https://auth.dnanexus.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/mmir/.pyenv/versions/g/lib/python3.12/site-packages/dxpy/scripts/dx.py\", line 324, in login\n",
      "    credentials = get_credentials(reuse=reuse, get_otp=using_otp)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mmir/.pyenv/versions/g/lib/python3.12/site-packages/dxpy/scripts/dx.py\", line 310, in get_credentials\n",
      "    username = input('Username [' + os.environ['DX_USERNAME'] + ']: ') or os.environ['DX_USERNAME']\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "EOFError: EOF when reading a line\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Username [mahdimir]: "
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'dx login\\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mCalledProcessError\u001B[0m                        Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mget_ipython\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_cell_magic\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbash\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdx login\u001B[39;49m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/g/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2541\u001B[0m, in \u001B[0;36mInteractiveShell.run_cell_magic\u001B[0;34m(self, magic_name, line, cell)\u001B[0m\n\u001B[1;32m   2539\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuiltin_trap:\n\u001B[1;32m   2540\u001B[0m     args \u001B[38;5;241m=\u001B[39m (magic_arg_s, cell)\n\u001B[0;32m-> 2541\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2543\u001B[0m \u001B[38;5;66;03m# The code below prevents the output from being displayed\u001B[39;00m\n\u001B[1;32m   2544\u001B[0m \u001B[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001B[39;00m\n\u001B[1;32m   2545\u001B[0m \u001B[38;5;66;03m# when the last Python token in the expression is a ';'.\u001B[39;00m\n\u001B[1;32m   2546\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(fn, magic\u001B[38;5;241m.\u001B[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001B[38;5;28;01mFalse\u001B[39;00m):\n",
      "File \u001B[0;32m~/.pyenv/versions/g/lib/python3.12/site-packages/IPython/core/magics/script.py:155\u001B[0m, in \u001B[0;36mScriptMagics._make_script_magic.<locals>.named_script_magic\u001B[0;34m(line, cell)\u001B[0m\n\u001B[1;32m    153\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    154\u001B[0m     line \u001B[38;5;241m=\u001B[39m script\n\u001B[0;32m--> 155\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshebang\u001B[49m\u001B[43m(\u001B[49m\u001B[43mline\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcell\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/g/lib/python3.12/site-packages/IPython/core/magics/script.py:315\u001B[0m, in \u001B[0;36mScriptMagics.shebang\u001B[0;34m(self, line, cell)\u001B[0m\n\u001B[1;32m    310\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m args\u001B[38;5;241m.\u001B[39mraise_error \u001B[38;5;129;01mand\u001B[39;00m p\u001B[38;5;241m.\u001B[39mreturncode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    311\u001B[0m     \u001B[38;5;66;03m# If we get here and p.returncode is still None, we must have\u001B[39;00m\n\u001B[1;32m    312\u001B[0m     \u001B[38;5;66;03m# killed it but not yet seen its return code. We don't wait for it,\u001B[39;00m\n\u001B[1;32m    313\u001B[0m     \u001B[38;5;66;03m# in case it's stuck in uninterruptible sleep. -9 = SIGKILL\u001B[39;00m\n\u001B[1;32m    314\u001B[0m     rc \u001B[38;5;241m=\u001B[39m p\u001B[38;5;241m.\u001B[39mreturncode \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m9\u001B[39m\n\u001B[0;32m--> 315\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CalledProcessError(rc, cell)\n",
      "\u001B[0;31mCalledProcessError\u001B[0m: Command 'b'dx login\\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "exome_folder = 'Population level exome OQFE variants, PLINK format - interim 200k release'\n",
    "exome_field_id = '23155'\n",
    "output_dir = '/Data/'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Import libraries and initialize Spark connection."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import databricks.koalas as ks\n",
    "import dxpy\n",
    "import dxdata\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "import re"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Initialize Spark\n",
    "# Spark initialization (Done only once; do not rerun this cell unless you select Kernel -> Restart kernel).\n",
    "sc = pyspark.SparkContext()\n",
    "spark = pyspark.sql.SparkSession(sc)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Load daatset description and select entity containing phenotypic data."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Automatically discover dispensed dataset ID and load the dataset\n",
    "dispensed_dataset = dxpy.find_one_data_object(typename = \"Dataset\" ,\n",
    "                                              name = \"app*.dataset\" ,\n",
    "                                              folder = \"/\" ,\n",
    "                                              name_mode = \"glob\")\n",
    "dispensed_dataset_id = dispensed_dataset[\"id\"]\n",
    "dataset = dxdata.load_dataset(id = dispensed_dataset_id)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "participant = dataset['participant']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Load cohorts that were created in cohort browser."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "case = dxdata.load_cohort(\"/Cohorts/diabetes_cases\")\n",
    "cont = dxdata.load_cohort(\"/Cohorts/diabetes_controls\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Specify fields ID to retrieve, get corresponding UKB RAP field names and print description table."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "field_ids = ['31' , '22001' , '22006' , '22019' , '22021' , '21022' , '41270']",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# This function is used to grab all field names (e.g. \"p<field_id>_iYYY_aZZZ\") of a list of field IDs\n",
    "def fields_for_id(field_id) :\n",
    "    from distutils.version import LooseVersion\n",
    "\n",
    "\n",
    "    field_id = str(field_id)\n",
    "    fields = participant.find_fields(name_regex = r'^p{}(_i\\d+)?(_a\\d+)?$'.format(\n",
    "            field_id))\n",
    "    return sorted(fields , key = lambda f : LooseVersion(f.name))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fields = [fields_for_id(f)[0] for f in field_ids] + [\n",
    "        participant.find_field(name = 'p20160_i0')] + [\n",
    "                 participant.find_field(name = 'eid')]\n",
    "field_description = pd.DataFrame({\n",
    "        'Field'  : [f.name for f in fields] ,\n",
    "        'Title'  : [f.title for f in fields] ,\n",
    "        'Coding' : [f.coding.codes if f.coding is not None else '' for f in\n",
    "                    fields]\n",
    "        })\n",
    "field_description"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Retrieve data for both cohorts."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "case_df = participant.retrieve_fields(fields = fields ,\n",
    "                                      filter_sql = case.sql ,\n",
    "                                      engine = dxdata.connect()).to_koalas()\n",
    "cont_df = participant.retrieve_fields(fields = fields ,\n",
    "                                      filter_sql = cont.sql ,\n",
    "                                      engine = dxdata.connect(dialect = \"hive+pyspark\" ,\n",
    "                                                              connect_args = {\n",
    "                                                                      'config' : {\n",
    "                                                                              'spark.kryoserializer.buffer.max'      : '256m' ,\n",
    "                                                                              'spark.sql.autoBroadcastJoinThreshold' : '-1'\n",
    "                                                                              }\n",
    "\n",
    "                                                                      })).to_koalas()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Create phenotype variable and concatenate cohorts into one dataframe."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "case_df['diabetes_cc'] = 1\n",
    "cont_df['diabetes_cc'] = 0"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "df = ks.concat([case_df , cont_df])",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df.diabetes_cc.value_counts()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of retrieved data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|    |     eid |   p21022 | p41270                                         | p41271   |   p20160_i0 |   p31 |   p22001 |   p22006 |   p22019 |   p22021 |   diabetes_cc |\n",
    "|---:|--------:|---------:|:-----------------------------------------------|:---------|------------:|------:|---------:|---------:|---------:|---------:|--------------:|\n",
    "|  0 | 1234567 |       67 | ['E119', 'M179', 'M431']                       |          |           0 |     0 |      nan |      nan |      nan |      nan |             1 |\n",
    "|  1 | 1234568 |       62 | ['E119', 'R15', 'R32', 'R55', 'Z922']          |          |           0 |     1 |        0 |        1 |      nan |        0 |             1 |\n",
    "|  2 | 1234569 |       50 | ['E119', 'I050', 'I080', 'I10', 'I270']        |          |           1 |     1 |        0 |      nan |      nan |        0 |             0 |\n",
    "|  3 | 1234570 |       60 | ['A099', 'D128', 'D70', 'E114', ]              |          |           1 |     0 |        1 |      nan |      nan |        0 |             0 |\n",
    "|  4 | 1234571 |       58 | ['A082',  'Z867', 'Z948', 'Z960']              |          |           0 |     1 |        1 |        1 |      nan |        0 |             0 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. QC samples based on several conditions."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df_qced = df[(df['p31'] == df[\n",
    "    'p22001']) &  # Filter in sex and genetic sex are the same           \n",
    "             (df[\n",
    "                  'p22006'] == 1) &  # in_white_british_ancestry_subset           \n",
    "             (df[\n",
    "                  'p22019'].isnull()) &  # Not Sex chromosome aneuploidy           \n",
    "             (df['p22021'] == 0)  # No kinship found\n",
    "             ]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df_qced.diabetes_cc.value_counts()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Rename columns and organize it in format suitable for PLINK and regenie."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Rename columns for better readibility\n",
    "df_qced = df_qced.rename(columns = {\n",
    "        'eid'       : 'IID' ,\n",
    "        'p31'       : 'sex' ,\n",
    "        'p21022'    : 'age' ,\n",
    "        'p20160_i0' : 'ever_smoked' ,\n",
    "        'p22006'    : 'ethnic_group' ,\n",
    "        'p22019'    : 'sex_chromosome_aneuploidy' ,\n",
    "        'p22021'    : 'kinship_to_other_participants'\n",
    "        })\n",
    "# Add FID column -- required input format for regenie \n",
    "df_qced['FID'] = df_qced['IID']\n",
    "\n",
    "# Create a phenotype table from our QCed data\n",
    "df_phenotype = df_qced[\n",
    "    ['FID' , 'IID' , 'diabetes_cc' , 'sex' , 'age' , 'ethnic_group' ,\n",
    "     'ever_smoked']]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df_phenotype = df_phenotype.to_pandas()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Select only samples that have WES data available and save them to CSV file."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Get WES\n",
    "path_to_family_file = f'/mnt/project/Bulk/Exome sequences/{exome_folder}/ukb{exome_field_id}_c1_b0_v1.fam'\n",
    "plink_fam_df = pd.read_csv(path_to_family_file ,\n",
    "                           delimiter = '\\s' ,\n",
    "                           dtype = 'object' ,\n",
    "                           names = ['FID' , 'IID' , 'Father ID' , 'Mother ID' ,\n",
    "                                    'sex' , 'Pheno'] ,\n",
    "                           engine = 'python')\n",
    "# Intersect the phenotype file and the 200K WES .fam file\n",
    "# to generate phenotype DataFrame for the 200K participants\n",
    "diabetes_wes_200k_df = df_phenotype.join(plink_fam_df.set_index('IID') ,\n",
    "                                         on = 'IID' ,\n",
    "                                         rsuffix = '_fam' ,\n",
    "                                         how = 'inner')\n",
    "# Drop unuseful columns from .fam file\n",
    "diabetes_wes_200k_df.drop(columns = ['FID_fam' , 'Father ID' , 'Mother ID' ,\n",
    "                                     'sex_fam' , 'Pheno'] ,\n",
    "                          axis = 1 ,\n",
    "                          inplace = True ,\n",
    "                          errors = 'ignore')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Write phenotype files to a TSV file\n",
    "diabetes_wes_200k_df.to_csv('diabetes_wes_200k.phe' ,\n",
    "                            sep = '\\t' ,\n",
    "                            na_rep = 'NA' ,\n",
    "                            index = False ,\n",
    "                            quoting = 3)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Load file to project storage."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%%bash -s \"$output_dir\"\n",
    "# Upload the geno-pheno intersect phenotype file back to the RAP project\n",
    "dx\n",
    "upload\n",
    "diabetes_wes_200k.phe - p - -path $1 - -brief"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of phenotype file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|    |     FID |     IID |   diabetes_cc |   sex |   age |   ethnic_group |   ever_smoked |\n",
    "|---:|--------:|--------:|--------------:|------:|------:|---------------:|--------------:|\n",
    "|  1 | 1234567 | 1234567 |             1 |     0 |    67 |              1 |             0 |\n",
    "|  4 | 1234568 | 1234568 |             1 |     1 |    62 |              1 |             0 |\n",
    "|  6 | 1234569 | 1234569 |             0 |     1 |    50 |              1 |             1 |\n",
    "| 19 | 1234570 | 1234570 |             0 |     0 |    60 |              1 |             1 |\n",
    "| 20 | 1234571 | 1234571 |             0 |     1 |    58 |              1 |             0 |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
